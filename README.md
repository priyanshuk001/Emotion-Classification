Here's a revised and personalized version of your README to reflect your ownership, coding style, and deployment context more clearly, while preserving technical accuracy and structure.

---

# ğŸ—£ï¸ Speech Emotion Recognition using Deep Learning

## ğŸ“Œ Objective

This project aims to build an end-to-end **speech emotion classification pipeline** that leverages deep learning and audio signal processing to detect emotions from human voice recordings. The solution supports both **speech and song-based input**, using robust feature extraction and a CNN-based classifier.

---

## ğŸš€ What This Project Does

* Extracts key audio features: MFCC, ZCR, RMSE
* Performs audio augmentation for better generalization
* Trains a custom 1D CNN for emotion classification
* Deploys an interactive **Streamlit web app** for:

  * Real-time single/batch predictions
  * Audio playback
  * Confidence visualization (pie/bar)
  * Downloadable CSV results

---

## ğŸ—ƒï¸ Dataset

**RAVDESS** (Ryerson Audio-Visual Database of Emotional Speech and Song)
ğŸ”— [Download here](https://zenodo.org/records/1188976#.XCx-tc9KhQI)

* ğŸ§ Total Samples: 9808 audio clips
* Emotions covered:

  * Neutral, Calm, Happy, Sad, Angry, Fearful, Disgust, Surprised

| Emotion   | Count |
| --------- | ----- |
| Calm      | 376   |
| Happy     | 376   |
| Sad       | 376   |
| Angry     | 376   |
| Fearful   | 376   |
| Disgust   | 192   |
| Surprised | 192   |
| Neutral   | 188   |

---

## ğŸ”¬ Methodology

### ğŸ§ Audio Preprocessing

* Sampling Rate: 22050 Hz
* Frame Length: 2048, Hop Length: 512
* Extracted Features:

  * MFCC (13 Coefficients)
  * Zero Crossing Rate
  * Root Mean Square Energy
* Combined Feature Vector Size: **2376**

### ğŸ§ª Data Augmentation

* Time Stretching
* Pitch Shifting
* White Noise Addition
* Audio Shifting
* Speed Change

### ğŸ§  Model Architecture

Custom 1D CNN:

* 5 Conv1D + BatchNorm + MaxPool layers
* Dropout layers for regularization
* Dense layer (512 units)
* Softmax output (8 emotion classes)
  ğŸ“Š **Trainable Params**: \~7.19 Million

### âš™ï¸ Training Setup

* Optimizer: Adam
* Loss Function: Categorical Crossentropy
* Batch Size: 64, Epochs: 40
* Learning Rate Scheduler: `ReduceLROnPlateau`

---

## ğŸ“ˆ Results

* âœ… **Test Accuracy:** 93.93%
* ğŸ“‰ **F1 Scores:**

  * Macro F1: 93.86%
  * Weighted F1: 93.94%
  * Micro F1: 93.93%

---

## ğŸŒ Streamlit Web Application

An interactive web app allows users to:

* ğŸ“¤ Upload single or multiple `.wav` files
* ğŸ§ Play audio interactively
* ğŸ“Š See predictions + confidence scores (bar/pie charts)
* ğŸ“ˆ View waveform and histograms
* â¬‡ï¸ Export batch results as CSV

### Live Features

* ğŸ”„ Auto model loading
* âš¡ Real-time inference
* ğŸ“Š Visual summaries of emotion distribution

---

## ğŸ“ Code Structure

```
ğŸ“¦ Emotion_Classifier_App/
â”œâ”€â”€ app.py                  # Streamlit Web App
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ cnn_model_full.keras #you can downlaod the model from drive link in models.md folder
â”‚   â”œâ”€â”€ scaler.pkl
â”‚   â””â”€â”€ encoder.pkl
â”œâ”€â”€ utils.py                # Feature extraction + helper functions
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ training_pipeline.ipynb
â”œâ”€â”€ requirements.txt
â””â”€â”€ assets/                 # Optional sample audio files
```

---

## ğŸ§ª How to Run Locally

### 1. Clone the repo

```bash
git clone https://github.com/your-username/emotion-classifier-app.git
cd emotion-classifier-app
```

### 2. Create a virtual environment

```bash
python -m venv venv
.\venv\Scripts\activate  # For Windows
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

### 4. Run the Streamlit app

```bash
streamlit run app.py
```

---

## ğŸ› ï¸ Tech Stack

* **Deep Learning**: TensorFlow, Keras
* **Audio**: Librosa
* **Visualization**: Plotly, Matplotlib, Seaborn
* **Web Interface**: Streamlit
* **Utilities**: Scikit-learn, NumPy, Pandas

---

## ğŸ™ Acknowledgements

* [RAVDESS Dataset](https://zenodo.org/record/1188976) by Ryerson University
* TensorFlow, Librosa, and the open-source ML community

---

